{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a3283d9-6aec-4e61-ad25-98dce4c0f662",
   "metadata": {},
   "source": [
    "This notebook is a collection of some things I've learned from GPT. It's a bit tricky without documentation so I hope that this can help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cdef6a-7bdd-4d48-9e4b-a6396c839774",
   "metadata": {},
   "source": [
    "I have tested and run this notebook on MIT supercloud. To take advantage of full memory usage, I recommend running this notebook on a full node vs. a small number of cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e391d37a-dee2-40c6-9642-1aa8ec1f8144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For installation instructions on MIT supercloud, see \n",
    "# https://gist.github.com/Sam-2727/3c283bd5d5521bde9742db198f03573e\n",
    "import gpt as g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c43510b-35c6-4709-8ace-00de294af9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some other packages we'll need\n",
    "import numpy as np\n",
    "import sys\n",
    "import io\n",
    "from os import path\n",
    "import struct\n",
    "from typing import Dict, List, Tuple\n",
    "from xml.etree import ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38695447-b3ed-4646-8d69-e401d26a6e35",
   "metadata": {},
   "source": [
    "GPT is divided into three components: fundamental objects, QCD (i.e. classical non-neural network algorithms and toolkit to calculate other quantities), and machine learning.\n",
    "\n",
    "Here I will mainly focus on the fundamental objects and QCD side of things, but I think learning the fundamental objects side of GPT is enough to then read and understand the machine learning code directly:\n",
    "https://github.com/lehner/gpt/tree/8dc512b219149d0362d9278e68cf4ef6733f1d4e/lib/gpt/ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a0ba0e-995f-4603-87cf-f7c189d6931e",
   "metadata": {},
   "source": [
    "# Fundamental GPT objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce97fe66-923b-48a2-a08b-bc6a47243e22",
   "metadata": {},
   "source": [
    "There are two objects of interest in GPT: grids and lattices. \n",
    "\n",
    "Grids are named in reference to the underlying package Grid on which GPT is built. They are more fundamental and encode the type of data we are working with and also some details about how we want to work with that data (mpi layout or checkerboarding).\n",
    "\n",
    "Lattices are wrapped on top of grid objects. They store specific instances of data we are working with and function in many respects like tensors (although tensors are different gpt objects). They can be indexed in many respects like numpy arrays, although there are a few differences, in particular how data is returned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13189862-4c85-4f46-a383-a8d93501543a",
   "metadata": {},
   "source": [
    "First let's create a grid object. The most basic instantiation of gpt grids is providing the spatial dimensions and float precision\n",
    "\n",
    "For full details of other parameters, see https://github.com/lehner/gpt/blob/8dc512b219149d0362d9278e68cf4ef6733f1d4e/lib/gpt/core/grid.py#L106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1193013-1b47-4289-847d-c0c3212f6d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new grid of size x=8,y=8,z=8,t=16\n",
    "# create with double precision floats\n",
    "newGrid = g.grid([8,8,8,16],precision=g.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92af8aa5-6741-4ee5-a3b9-7e28606e1408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fdimensions = [8, 8, 8, 16]; mpi = [1, 1, 1, 1]; precision = double; checkerboard = full\n"
     ]
    }
   ],
   "source": [
    "print(newGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51aa0b1b-c161-4b45-b8b8-4c142095e634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gpt.core.grid.grid at 0x7f17b4684610>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c009b7-0bdb-40fe-a490-7e8021388d77",
   "metadata": {},
   "source": [
    "Note that printing a grid in a notebook is more informative than just calling it (which is sometimes erronously thought to be equivalent to printing in Jupyter notebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba54f9a-e37f-472e-962e-73f9188fc217",
   "metadata": {},
   "source": [
    "Now let's create a lattice object. We need to create the lattice on top of our grid, and because lattice objects can be thought of in many respects as tensors, we need to specify what type of tensor we want. Note that because the spatial lattice sites are already specified in the grid object, we don't need to specify these when creating the lattice object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c70fd7c8-054e-46c4-b5cb-79a17bfd113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are creating a matrix object of spin and color.\n",
    "# So at each point in spacetime we associate a (4x4x3x3)\n",
    "# tensor (or 12x12 matrix).\n",
    "newLattice = g.mspincolor(newGrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a85ce4b-3d52-4018-b6d6-465caf3afd26",
   "metadata": {},
   "source": [
    "do NOT try printing lattice objects. GPT will try printing our every entry in the lattice. Instead, if you want to see what type of lattice you are working with, just call the object as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "118c60b6-714d-46a4-b4ce-700224ba6556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lattice(ot_matrix_spin_color(4,3),double)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newLattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0caa2ed-fb37-443d-97b9-e10ce4c82301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fdimensions = [8, 8, 8, 16]; mpi = [1, 1, 1, 1]; precision = double; checkerboard = full\n"
     ]
    }
   ],
   "source": [
    "print(newLattice.grid) # check that this matches the grid we inputted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4290d90b-130a-44ef-ac10-59584f3de702",
   "metadata": {},
   "source": [
    "We can index lattice matrix sites as [x,y,z,t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b95023b8-e0ec-49c5-8cee-43b546f79595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4, 3, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newLattice[1,2,3,4].array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8d8aef-6452-403a-a77a-aebd7892e201",
   "metadata": {},
   "source": [
    "Once the lattice is indexed, we convert to a numpy array with the .array attribute, then find the shape of the returned numpy array. We see that the convention is [spin,spin,color,color]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed25fdf-8532-47c2-8764-d2e934a51dc9",
   "metadata": {},
   "source": [
    "We can access the values at specific lattice sites by accessing the lattice object directly.\n",
    "\n",
    "Let's look at the color-color matrix associated with [x,y,z,t,s1,s2]=[1,2,3,4,3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da97f142-be66-4722-b1c3-2320b6e07cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[0.+0.j, 0.+0.j, 0.+0.j],\n",
       "          [0.+0.j, 0.+0.j, 0.+0.j],\n",
       "          [0.+0.j, 0.+0.j, 0.+0.j]]]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newLattice[1,2,3,4,3,2,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc05ffc-8abd-4b4d-974c-c66b0800d312",
   "metadata": {},
   "source": [
    "One subtly is that when we access only spacetime indices [x,y,z,t], the object returned is a gpt tensor object which we need to convert to a numpy array, but when accessing also the underlying spin-color indices, the returned object is a numpy array. So newLattice[1,2,3,4,:,:,:,:] and newLattice[1,2,3,4].array return the same thing, but but the second is a bit faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a50dc2-4523-4b81-b0fb-261634446271",
   "metadata": {},
   "source": [
    "Everything is zero now in our instantiation, but we can change that by providing a numpy array.\n",
    "\n",
    "We need to make sure that our numpy array has the correct data type. Because we said that our data type was g.double, our numpy data type should be np.cdouble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8c28ab40-8bc7-44a9-bd83-f02becf5fe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   +0.j 0.125+0.j 0.25 +0.j]\n",
      " [0.375+0.j 0.5  +0.j 0.625+0.j]\n",
      " [0.75 +0.j 0.875+0.j 1.   +0.j]]\n"
     ]
    }
   ],
   "source": [
    "arrayInput = np.reshape(np.linspace(0,1,9,dtype=np.cdouble),(3,3))\n",
    "print(arrayInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6710201-b85a-4313-ac26-bc6a4a3af670",
   "metadata": {},
   "outputs": [],
   "source": [
    "newLattice[1,2,3,4,3,2,:,:]=arrayInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e14038c-3a74-43df-8879-11f946b91bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[0.   +0.j, 0.125+0.j, 0.25 +0.j],\n",
       "          [0.375+0.j, 0.5  +0.j, 0.625+0.j],\n",
       "          [0.75 +0.j, 0.875+0.j, 1.   +0.j]]]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newLattice[1,2,3,4,3,2,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c389b6e2-710d-452b-8df5-056559f551f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[0.+0.j, 1.+0.j, 2.+0.j],\n",
       "          [3.+0.j, 4.+0.j, 5.+0.j],\n",
       "          [6.+0.j, 7.+0.j, 8.+0.j]]]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newLattice[1,2,3,4,0,0,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ad647b-ea98-4882-861e-458bf1776d38",
   "metadata": {},
   "source": [
    "**Important point:** Converting between numpy arrays and gpt objects is extremely slow, so it is best to work with just gpt objects or just numpy arrays whenever possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "72ac7ead-5f30-441b-bee1-3aa4ea812af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.57 s ± 153 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit newLattice[1,2,3,4,3,2,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc9c8dd-d031-4e1b-a225-9ffbe4e6f73f",
   "metadata": {},
   "source": [
    "### Some more lattice operations (useful for energy calculations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1fde0d-7676-48e7-91b6-58204eb11887",
   "metadata": {},
   "source": [
    "Fortunately, we can perform most numpy operations on lattice objects, although things are usually a bit more brittle. Often, lattice operations are named\n",
    "\n",
    "For example, we can multiply two lattices together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f7d37c2b-c1f9-4cea-afa7-68a09fd51c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we get a nonzero answer\n",
    "numpyInput = np.reshape(np.arange(0,144,dtype=np.cdouble),(4,4,3,3))\n",
    "newLattice[1,2,3,4,:,:,:,:]=numpyInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2e42c42a-e05b-491d-93c8-48e75acfd0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "expressionToEvaluate = newLattice*newLattice\n",
    "newLatticeSquared = g(expressionToEvaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce4ded2-966c-495b-9419-f1347e4b97b9",
   "metadata": {},
   "source": [
    "GPT only evaluates expressions when wrapped with g(), so you can control where in your code you want the computationally intensive evaluation to occur.\n",
    "\n",
    "The expression evaluation takes place as a tensor sum at each lattice site (unlike default numpy multiplication). So \n",
    "\n",
    "$L[x,y,z,t,s_1,s_3,c_1,c_3]=\\sum_{s_2,c_2}L[x,y,z,t,s_1,s_2,c_1,c_2]L[x,y,z,t,s_2,s_3,c_2,c_3]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eb51ee25-73ce-4a4b-8b90-74a63b724e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14802+0j)\n"
     ]
    }
   ],
   "source": [
    "# what we expect\n",
    "summedResult = 0\n",
    "for s in range(0,4):\n",
    "    for c in range(0,3):\n",
    "        summedResult+=numpyInput[0,s,0,c]*numpyInput[s,0,c,0]\n",
    "print(summedResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "50e21079-2148-42d6-b271-320342ff0e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[14802.+0.j]]]]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirming result\n",
    "newLatticeSquared[1,2,3,4,0,0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfcee5c-a4e3-497a-9440-fe8282e2a314",
   "metadata": {},
   "source": [
    "It should be mentioned briefly that vectors also exist in GPT, although I haven't used them too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c4eb2101-4cbc-4591-aa16-e74a48311293",
   "metadata": {},
   "outputs": [],
   "source": [
    "newLatticeVector = g.vspincolor(newGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2134eb19-3b60-4478-a755-7edc4ee22621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lattice(ot_vector_spin_color(4,3),double)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g(newLattice*newLatticeVector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b27556-3a5a-48e9-b080-300b84980269",
   "metadata": {},
   "source": [
    "We'll come back to some more fundamental GPT operations in the course of things, but first:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af76c9-207c-4253-be2f-fdd685356423",
   "metadata": {},
   "source": [
    "# Generating propagators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc114ed5-42a6-478a-93d7-8330f7575cb0",
   "metadata": {},
   "source": [
    "We will load in gauge configurations from previous computations in chroma. We could also compute in gpt, but that would take too long for a tutorial Jupyter notebook.\n",
    "\n",
    "For a good tutorial on HMC gauge generation for pseudofermions of a two-flavor degenerate mass action, see https://homepages.uni-regensburg.de/~lec17310/teaching/wise2122/chapter13.pdf \n",
    "\n",
    "Note that in that tutorial, if wilson fermions are being used, some code should be changed. In particular, we should replace D_m with wilson_clover (as specified below in the propagator computation section), and critically, two_flavor_ratio_evenodd_schur with two_flavor_evenodd_schur and [D_m,D_pv] with D_m."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8277a54-d1a1-443c-b7af-018f4171a619",
   "metadata": {},
   "source": [
    "gauge configurations from chroma have some xml data before containing binary data. When reading them into gpt, we need to skip to the end of the xml and then load the binary data into a numpy array. We then put that numpy array into a lattice object before saving for later usage.\n",
    "\n",
    "The only thing that might need modifying is that \">c8\" command, depending on the data-precision used. See https://numpy.org/doc/stable/reference/arrays.dtypes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f3fea941-48e4-48ef-8b13-f82d0e2a2cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import gpt as g\n",
    "import io\n",
    "from os import path\n",
    "import struct\n",
    "from typing import Dict, List, Tuple\n",
    "from xml.etree import ElementTree as ET\n",
    "def loadGauge(path,size):\n",
    "    filename = path\n",
    "    with open(filename, \"rb\") as f:\n",
    "        meta: Dict[str, Tuple[int]] = {}\n",
    "        buffer = f.read(8)\n",
    "        while buffer != b\"\" and buffer != b\"\\x0A\":\n",
    "            assert buffer.startswith(b\"\\x45\\x67\\x89\\xAB\\x00\\x01\")\n",
    "            length = (struct.unpack(\">Q\", f.read(8))[0] + 7) // 8 * 8\n",
    "            name = f.read(128).strip(b\"\\x00\").decode(\"utf-8\")\n",
    "            meta[name] = (f.tell(), length)\n",
    "            f.seek(length, io.SEEK_CUR)\n",
    "            buffer = f.read(8)\n",
    "        f.seek(meta[\"scidac-private-record-xml\"][0])\n",
    "        #previously used scidac_private_record_xml but no longer used (can remove)\n",
    "        scidac_private_record_xml = ET.ElementTree(\n",
    "            ET.fromstring(f.read(meta[\"scidac-private-record-xml\"][1]).strip(b\"\\x00\").decode(\"utf-8\"))\n",
    "        )   \n",
    "        f.seek(meta[\"ildg-binary-data\"][0])\n",
    "        ildg_binary_data = f.read(meta[\"ildg-binary-data\"][1])\n",
    "        # here, all we're doing is finding where the header ends and the binary data we want to read begins\n",
    "    Lt,Lz,Ly,Lx,Nl,Nc = size\n",
    "    u_raw2 = (\n",
    "                np.frombuffer(ildg_binary_data, \">c8\")\n",
    "                .reshape( Lt, Lz, Ly, Lx, Nl, Nc,Nc)\n",
    "                .astype(\">c8\")\n",
    "            )\n",
    "    # might need to modify \"c8\" depending on float precision used.\n",
    "    # also be careful on time, space order. Might be different depending on your usage.\n",
    "    u_raw3 = u_raw2.astype(np.complex128)\n",
    "    rng = g.random(\"test\", \"vectorized_ranlux24_24_64\")\n",
    "    grid = g.grid([size[3],size[2],size[1],size[0]],precision=g.double)\n",
    "    U = g.qcd.gauge.random(grid, rng)\n",
    "    for i in range(0,4):\n",
    "        gauge_raw = u_raw3[:,:,:,:,i,:,:]\n",
    "        U[i][:]=np.ravel(gauge_raw)\n",
    "    return U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265bfcd0-3397-4d4d-a4b0-351dd0b48de1",
   "metadata": {},
   "source": [
    "We now load a sample gauge configuration. \n",
    "\n",
    "**Important**: the order of time, space is reversed in chroma and gpt typical conventions (although of course these are just conventions). When reading the chroma file above, time goes first, so when specifying size for above function, time goes first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "997d3de8-dbe4-4c4c-a6ba-72327af91a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT :    9847.934131 s : Initializing gpt.random(test,vectorized_ranlux24_24_64) took 0.204818 s\n"
     ]
    }
   ],
   "source": [
    "# change filename as needed\n",
    "i = 0 \n",
    "loadGaugeTest = loadGauge(\"sampleConfig.lime\",(48,24,24,24,4,3))\n",
    "# note that time goes first: [t,x,y,z]=[48,24,24,24]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d99bf0-cda5-43cd-bcf9-e7780be02e42",
   "metadata": {},
   "source": [
    "we can save this gauge configuration in GPT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d52f4738-083f-4949-bb4e-0c8a66dc3936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT :   10090.751025 s : Switching view to [1,1,1,1]/Write\n",
      "GPT :   10092.705766 s : Wrote 0.0889893 GB at 0.0455256 GB/s (0.0510122 GB/s for distribution, 1.86079 GB/s for checksum, 0.758947 GB/s for writing, 1 views per node)\n",
      "GPT :   10092.884791 s : Wrote 0.0889893 GB at 0.512146 GB/s (1.3092 GB/s for distribution, 3.19029 GB/s for checksum, 1.14347 GB/s for writing, 1 views per node)\n",
      "GPT :   10093.069519 s : Wrote 0.0889893 GB at 0.485227 GB/s (1.59818 GB/s for distribution, 3.7069 GB/s for checksum, 0.858527 GB/s for writing, 1 views per node)\n",
      "GPT :   10093.283637 s : Wrote 0.0889893 GB at 0.42336 GB/s (1.01458 GB/s for distribution, 2.04426 GB/s for checksum, 1.12791 GB/s for writing, 1 views per node)\n",
      "GPT :   10093.342481 s : Completed writing sampleConfigGPT in 2.61559 s\n"
     ]
    }
   ],
   "source": [
    "g.save(\"sampleConfigGPT\",loadGaugeTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98faa34e-8faa-4ddf-b1f0-1ed3b1bfa365",
   "metadata": {},
   "source": [
    "GPT has stored the field configuration with double precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f1172916-86c2-4801-acf2-9faa403640f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191116392\n",
      "382206172\n"
     ]
    }
   ],
   "source": [
    "print(path.getsize(\"sampleConfig.lime\"))\n",
    "print(path.getsize(\"sampleConfigGPT/00/0000000000.field\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343ce4ab-5b2d-470b-a82e-67cd9a675940",
   "metadata": {},
   "source": [
    "# Calculating Propagators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d713e0-2b46-4a8b-9285-f1433db406da",
   "metadata": {},
   "source": [
    "We compute the propagator corresponding to our gauge field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489f7ead-1234-4b54-895f-00214e8b8d19",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "We specifiy parameters for our wilson_clover action. \n",
    "\n",
    "These can be read from the chroma xml header or specified in the gauge generation to begin with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e1610215-761a-4517-94b3-d4f870da8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mass = -0.2450\n",
    "csw = 1.24930970916466\n",
    "parameters = {\n",
    "                \"mass\":mass,\n",
    "                \"boundary_phases\":[1,1,1,-1],\n",
    "                \"csw_t\":csw,\n",
    "                \"csw_r\":csw,\n",
    "                \"xi_0\":1,\n",
    "                \"nu\":1,\n",
    "                \"isAnisotropic\":False\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeec2a4-e089-4076-b897-d2fc3c2813bb",
   "metadata": {},
   "source": [
    "The chroma header for our gauge configurations specifies that one smearing step of 0.125 is applied. We create a smearing operator sm and then apply U to it. In general this is how objects in gauge work. First we need to instantiate a specific instance of the object which we call an operator, and then apply the operator to the object of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1885f11b-79a9-48c1-aeee-cea7d38df46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sm = g.qcd.gauge.smear.stout(rho=0.125)\n",
    "U = sm(loadGaugeTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9acb7a0-212f-40cc-a4bd-ca4ed253ce1b",
   "metadata": {},
   "source": [
    "Now we instantiate our wilson_clover action term. If in doubt of the parameters of a function, it's best to look at the raw code. In this case:\n",
    "https://github.com/lehner/gpt/blob/8dc512b219149d0362d9278e68cf4ef6733f1d4e/lib/gpt/qcd/fermion/wilson.py#L75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "539723e5-9d38-471e-b72f-75c5eb57f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_m = g.qcd.fermion.wilson_clover(U, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594aec57-f49f-4fc5-b020-ba6b7d3e38f0",
   "metadata": {},
   "source": [
    "There are a lot of different methods for propagator inversion in gpt. In particular, some interesting things have been done with multigrid and machine learning. I just use an even odd preconditioner and the fgcr inversion algorithm (but without SAP like is done in some cases). This works well enough for large lattice spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8d7eb6c5-06d3-4ec3-8303-bd26e7ace447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining some shortcuts\n",
    "inv = g.algorithms.inverter\n",
    "inv_pc = inv.preconditioned\n",
    "pc = g.qcd.fermion.preconditioner\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631043e2-63ab-47f8-9967-6258ee28fd91",
   "metadata": {},
   "source": [
    "First we instantiate our inverter algorithm, specifying our tolerance ($10^{-12}$), maximum number of iterations, and restart length (parameter relevant to details of inverter algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e7656408-7983-4bff-ae74-074fe1794f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fgcr = inv.fgcr({\"eps\": 1e-12, \"maxiter\": 1024, \"restartlen\": 8})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfd8838-bb89-427a-894f-26e6d7ce7e7d",
   "metadata": {},
   "source": [
    "We can now create our inversion operator with even odd preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a0fdf39a-7985-466a-b3d7-d3cc1baa9c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = inv_pc(pc.eo2(), fgcr)\n",
    "inv_w = inv(D_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086128ea-f7db-4fc6-af0e-6c2533a2bd1f",
   "metadata": {},
   "source": [
    "We take the grid corresponding to our gauge field and create a lattice object that will store our propagator. We then add a point source at (x,y,z,t)=(0,0,0,0). Alternatively we could've created a wall source or smeared.\n",
    "\n",
    "Search gpt code for \"gpt.create\" for other options (e.g. g.create.wall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763f66d0-67b2-4f43-9d02-0ac5e538eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = U2[0].grid\n",
    "src = g.mspincolor(grid)\n",
    "src[:]=0\n",
    "g.create.point(src, (0,0,0,0))\n",
    "prop = g(inv_w * src)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce77614a-4786-4c7c-b318-8ee664f0e9de",
   "metadata": {},
   "source": [
    "# Correlation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668ddafe-d95f-426f-aa31-dac6e5a357f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
